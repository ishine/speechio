logging: config/logging.yaml

data_zoo: data/audio/zoo.yaml

sample_loader:
    field_map:
        id: ID
        audio: AUDIO
        begin: BEGIN
        duration: DURATION
        text: TEXT
        speaker: SPEAKER
    min_duration: 0.5
    max_duration: 20.0
    min_text_length: 1
    max_text_length: 1024

dataset:
    train:
        subsets:
        -   id: AISHELL-1-TRAIN
            max_num_samples: -1

    valid:
        subsets:
        -   id: AISHELL-1-DEV
            max_num_samples: 20

    test:
        subsets:
        -   id: AISHELL-1-TEST
            max_num_samples: 0

resampler:
    sample_rate: 16000

perturbation:
    mark_key: True
    speeds: #[0.9, 1.0, 1.1]
    tempos: #[0.9, 1.0, 1.1]
    volumes: #[0.9, 1.0, 1.1]

feature_type: fbank # support fbank only now
feature_extractors:
    fbank:
        dither: 0.0
        num_mel_bins: 80
    hires_mfcc:
        dither: 0.0
        num_mel_bins: 40
        num_ceps: 40
        low_freq: 20
        high_freq: -400

text_normalizer:
    case: UPPER # either 'UPPER' or 'lower'

tokenizer:
    model: model/tokenizer/AISHELL-1.model

dataloader:
    num_workers: 8
    shuffle: True
    drop_last: False
    batch_size: 8

# training
num_epochs: 30
gradient_accumulation: 2
gradient_clipping: 5.0
log_interval: 100
optimizer:
    Adam:
        lr: 0.001
scheduler:
    warmup_steps: 25000

# model
model:
    encoder: conformer
    encoder_conf:
        output_size: 256    # dimension of attention
        attention_heads: 4
        linear_units: 2048  # the number of units of position-wise feed forward
        num_blocks: 12      # the number of encoder blocks
        dropout_rate: 0.1
        positional_dropout_rate: 0.1
        attention_dropout_rate: 0.0
        input_layer: conv2d # encoder input type, you can chose conv2d, conv2d6 and conv2d8
        normalize_before: true
        cnn_module_kernel: 15
        use_cnn_module: True
        activation_type: 'swish'
        pos_enc_layer_type: 'rel_pos'
        selfattention_layer_type: 'rel_selfattn'
        causal: true
        use_dynamic_chunk: true
        cnn_module_norm: 'layer_norm' # using nn.LayerNorm makes model converge faster
        use_dynamic_left_chunk: false

    # decoder related
    decoder: transformer
    decoder_conf:
        attention_heads: 4
        linear_units: 2048
        num_blocks: 6
        dropout_rate: 0.1
        positional_dropout_rate: 0.1
        self_attention_dropout_rate: 0.0
        src_attention_dropout_rate: 0.0

    # hybrid CTC/attention
    model_conf:
        ctc_weight: 0.3
        lsm_weight: 0.1     # label smoothing option
        length_normalized_loss: false

