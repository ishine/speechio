#!/usr/bin/env python3
# Copyright (c) 2021 Jiayu DU
# All rights reserved.

import sys, os
import argparse
from contextlib import contextmanager

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--backend', choices = ['sentencepiece'], default = 'sentencepiece')
    parser.add_argument('--model', type = str, required = True)
    parser.add_argument('--input', type = str, default = '-')
    parser.add_argument('--output', type = str, default = '-')
    parser.add_argument('--output_format', choices=['piece', 'id'], default = 'piece')
    args = parser.parse_args()
    print(args, file=sys.stderr)

    @contextmanager
    def open_istream(fname):
        if fname == '-':
            yield sys.stdin
        else:
            yield open(fname, 'r', encoding='utf8')

    @contextmanager
    def open_ostream(fname):
        if fname == '-':
            yield sys.stdout
        else:
            yield open(fname, 'w+', encoding='utf8')

    if args.backend == 'sentencepiece':
        import sentencepiece as spm
        # https://colab.research.google.com/github/google/sentencepiece/blob/master/python/sentencepiece_python_module_example.ipynb

        sp = spm.SentencePieceProcessor()
        sp.load(args.model + '.model')

        with open_istream(args.input) as istream, open_ostream(args.output) as ostream:
            for l in istream:
                if args.output_format == 'piece':
                    pieces = sp.EncodeAsPieces(l.strip())
                    encoded = ' '.join(pieces)
                elif args.output_format == 'id':
                    ids = sp.EncodeAsIds(l.strip())
                    encoded = ' '.join([ str(x) for x in ids ])
                else:
                    raise NotImplementedError

                print(encoded, file = ostream)

    else:
        raise NotImplementedError(F'Unsupported tokenizer backend: {args.backend}')
