#!/usr/bin/env python3

import sys, os
import argparse
from omegaconf import OmegaConf

REMOVE_LIST = [
    '<blk>', '<blank>', '<pad>',
    '<s>', '<bos>', '<sos>',
    '</s>', '<eos>',
    '<unk>', '<UNK>',
]

if __name__ == '__main__':
    parser = argparse.ArgumentParser()

    parser.add_argument('--dryrun', type = bool, default = False)
    parser.add_argument('--config', type = str, required = True)
    parser.add_argument('--text', type = str, required = True, help = 'input text (tokenized)')
    parser.add_argument('--vocab', type = str, required = True, help = 'input tokenizer, need its vocabulary')
    parser.add_argument('--model', type = str, required = True, help = 'output path prefix, e.g. egs/stt/lm{.vocab, .arpa, .trie}')

    args = parser.parse_args()
    print(args, file = sys.stderr)

    config = OmegaConf.load(args.config)
    print(f'LM config: {config}', file = sys.stderr)

    if config.model_type == 'ngram':
        opts = config["kenlm"]

        lm_vocab = args.model + '.vocab'
        lm_arpa = args.model + '.arpa'
        lm_binary = args.model + f'.{opts["build_type"]}'

        # 1. Generate LM vocabulary from tokenizer's vocabulary
        tokens = []
        with open(args.vocab, 'r', encoding='utf8') as f:
            for l in f:
                if (len(cols := l.strip().split()) == 2):
                    tokens.append(cols[0])
        print(f'Tokenizer size: {len(tokens)}', file = sys.stderr)

        words = []
        with open(lm_vocab, 'w+', encoding='utf8') as f:
            for token in tokens:
                if token not in REMOVE_LIST:
                    words.append(token)
                    print(token, file = f)
        print(f'Vocabulary size: {len(words)}', file = sys.stderr)

        # 2. Train ngram arpa model
        train_cmd = f'cat {lm_vocab} {args.text} | lmplz {opts["train_opts"]} --limit_vocab_file {lm_vocab} > {lm_arpa}'
        print(train_cmd, file = sys.stderr)
        if not args.dryrun:
            os.system(train_cmd)

        # 3. Build KenLM binary out of trained arpa model
        build_cmd = f'build_binary {opts["build_opts"]} {opts["build_type"]} {lm_arpa} {lm_binary}'
        print(build_cmd, file = sys.stderr)
        if not args.dryrun:
            os.system(build_cmd)
    else:
        raise NotImplementedError

